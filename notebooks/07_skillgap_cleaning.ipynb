{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Skill Gap Analyzer\n",
        "# 07_skillgap_cleaning.ipynb\n",
        "# Cell 1: Load Data & Basic Text Cleaning\n",
        "# =========================================\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Load datasets\n",
        "job_df = pd.read_csv(\"monster_com-job_sample.csv\")\n",
        "resume_df = pd.read_csv(\"UpdatedResumeDataSet.csv\")\n",
        "\n",
        "print(\"Initial Shapes:\")\n",
        "print(\"Job data:\", job_df.shape)\n",
        "print(\"Resume data:\", resume_df.shape)\n",
        "\n",
        "# Keep only required columns\n",
        "job_df = job_df[[\"job_title\", \"job_description\"]].dropna()\n",
        "resume_df = resume_df[[\"Category\", \"Resume\"]].dropna()\n",
        "\n",
        "print(\"\\nAfter column selection:\")\n",
        "print(\"Job data:\", job_df.shape)\n",
        "print(\"Resume data:\", resume_df.shape)\n",
        "\n",
        "# Basic text cleaning function\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-zA-Z\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "# Apply cleaning\n",
        "job_df[\"clean_description\"] = job_df[\"job_description\"].apply(clean_text)\n",
        "resume_df[\"clean_resume\"] = resume_df[\"Resume\"].apply(clean_text)\n",
        "\n",
        "print(\"\\nSample cleaned job text:\\n\")\n",
        "print(job_df[\"clean_description\"].iloc[0][:500])\n",
        "\n",
        "print(\"\\nSample cleaned resume text:\\n\")\n",
        "print(resume_df[\"clean_resume\"].iloc[0][:500])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oKi1qP6hjTgK",
        "outputId": "7369294f-4a5e-47ac-d37d-649bac079030"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Shapes:\n",
            "Job data: (22000, 14)\n",
            "Resume data: (962, 2)\n",
            "\n",
            "After column selection:\n",
            "Job data: (22000, 2)\n",
            "Resume data: (962, 2)\n",
            "\n",
            "Sample cleaned job text:\n",
            "\n",
            "teamsoft is seeing an it support specialist to join our client in madison wi the ideal candidate must have at least years of experience in the field they need to be familiar with a variety of the field s concepts practices and procedures as this position relies on extensive experience and judgment to plan and accomplish goals required skills call tracking software phone based technical support problem documentation and communication remote desktop management tools respond to customer requests ge\n",
            "\n",
            "Sample cleaned resume text:\n",
            "\n",
            "skills programming languages python pandas numpy scipy scikit learn matplotlib sql java javascript jquery machine learning regression svm na ve bayes knn random forest decision trees boosting techniques cluster analysis word embedding sentiment analysis natural language processing dimensionality reduction topic modelling lda nmf pca neural nets database visualizations mysql sqlserver cassandra hbase elasticsearch d js dc js plotly kibana matplotlib ggplot tableau others regular expression html c\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U07PPC5ahPh8",
        "outputId": "347addba-7580-4651-b8b4-14ef5ece155a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample job text after stopword removal:\n",
            "\n",
            "teamsoft seeing support specialist join client madison wi ideal candidate must least years experience field need familiar variety field concepts practices procedures position relies extensive experience judgment plan accomplish goals required skills call tracking software phone based technical support problem documentation communication remote desktop management tools respond customer requests general understanding landesk microsoft office suitefind teamsoft madison area technology leader consul\n",
            "\n",
            "Sample resume text after stopword removal:\n",
            "\n",
            "skills programming languages python pandas numpy scipy scikit learn matplotlib sql java javascript jquery machine learning regression svm na bayes knn random forest decision trees boosting techniques cluster analysis word embedding sentiment analysis natural language processing dimensionality reduction topic modelling lda nmf pca neural nets database visualizations mysql sqlserver cassandra hbase elasticsearch js dc js plotly kibana matplotlib ggplot tableau others regular expression html css an\n"
          ]
        }
      ],
      "source": [
        "# =========================================\n",
        "# Cell 2: Stopwords Removal\n",
        "# =========================================\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords (first time only)\n",
        "nltk.download(\"stopwords\")\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "# Remove stopwords function\n",
        "def remove_stopwords(text):\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "# Apply stopwords removal\n",
        "job_df[\"clean_description_nostop\"] = job_df[\"clean_description\"].apply(remove_stopwords)\n",
        "resume_df[\"clean_resume_nostop\"] = resume_df[\"clean_resume\"].apply(remove_stopwords)\n",
        "\n",
        "print(\"Sample job text after stopword removal:\\n\")\n",
        "print(job_df[\"clean_description_nostop\"].iloc[0][:500])\n",
        "\n",
        "print(\"\\nSample resume text after stopword removal:\\n\")\n",
        "print(resume_df[\"clean_resume_nostop\"].iloc[0][:500])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Cell 3: Skill Keyword Extraction\n",
        "# =========================================\n",
        "\n",
        "# Common technical skill vocabulary (expandable later)\n",
        "skill_keywords = [\n",
        "    \"python\", \"java\", \"sql\", \"javascript\", \"html\", \"css\",\n",
        "    \"machine learning\", \"deep learning\", \"data analysis\",\n",
        "    \"pandas\", \"numpy\", \"scikit\", \"sklearn\", \"tensorflow\",\n",
        "    \"keras\", \"docker\", \"git\", \"linux\", \"aws\", \"azure\",\n",
        "    \"nlp\", \"computer vision\", \"tableau\", \"power bi\",\n",
        "    \"excel\", \"spark\", \"hadoop\"\n",
        "]\n",
        "\n",
        "# Function to extract skills from text\n",
        "def extract_skills(text, skill_list):\n",
        "    found = set()\n",
        "    for skill in skill_list:\n",
        "        if skill in text:\n",
        "            found.add(skill)\n",
        "    return list(found)\n",
        "\n",
        "# Apply extraction\n",
        "job_df[\"job_skills\"] = job_df[\"clean_description_nostop\"].apply(\n",
        "    lambda x: extract_skills(x, skill_keywords)\n",
        ")\n",
        "\n",
        "resume_df[\"resume_skills\"] = resume_df[\"clean_resume_nostop\"].apply(\n",
        "    lambda x: extract_skills(x, skill_keywords)\n",
        ")\n",
        "\n",
        "print(\"Sample job extracted skills:\")\n",
        "print(job_df[\"job_skills\"].iloc[0])\n",
        "\n",
        "print(\"\\nSample resume extracted skills:\")\n",
        "print(resume_df[\"resume_skills\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8Nwe0gakLJI",
        "outputId": "42752920-200c-481a-a017-55c7067387ae"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample job extracted skills:\n",
            "[]\n",
            "\n",
            "Sample resume extracted skills:\n",
            "['machine learning', 'numpy', 'sql', 'tableau', 'git', 'pandas', 'css', 'java', 'python', 'html', 'deep learning', 'scikit', 'computer vision', 'docker', 'javascript']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Cell 4: Improved Skill Extraction for Jobs\n",
        "# =========================================\n",
        "\n",
        "# Expanded & normalized skill vocabulary\n",
        "skill_keywords = [\n",
        "    # programming\n",
        "    \"python\", \"java\", \"c++\", \"c#\", \"sql\", \"javascript\",\n",
        "    # data / ml\n",
        "    \"machine learning\", \"deep learning\", \"data analysis\",\n",
        "    \"data science\", \"nlp\", \"computer vision\",\n",
        "    # libraries\n",
        "    \"pandas\", \"numpy\", \"scikit\", \"sklearn\",\n",
        "    # tools\n",
        "    \"git\", \"docker\", \"linux\", \"aws\", \"azure\",\n",
        "    \"tableau\", \"power bi\", \"excel\",\n",
        "    # it / support\n",
        "    \"microsoft office\", \"remote desktop\",\n",
        "    \"technical support\", \"networking\", \"troubleshooting\"\n",
        "]\n",
        "\n",
        "def extract_skills_loose(text, skill_list):\n",
        "    found = set()\n",
        "    for skill in skill_list:\n",
        "        # match partial phrases as well\n",
        "        if any(word in text for word in skill.split()):\n",
        "            if skill in text:\n",
        "                found.add(skill)\n",
        "    return list(found)\n",
        "\n",
        "# Re-extract job skills\n",
        "job_df[\"job_skills\"] = job_df[\"clean_description_nostop\"].apply(\n",
        "    lambda x: extract_skills_loose(x, skill_keywords)\n",
        ")\n",
        "\n",
        "print(\"Improved job extracted skills (sample):\")\n",
        "print(job_df[\"job_skills\"].iloc[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cubRLNvol93M",
        "outputId": "6c139769-f2a6-4e85-a941-4057b208d16b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Improved job extracted skills (sample):\n",
            "['microsoft office', 'technical support', 'remote desktop']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# Cell 5: Skill Gap Calculation\n",
        "# =========================================\n",
        "\n",
        "# Select one sample job & resume (for demo)\n",
        "job_required_skills = set(job_df[\"job_skills\"].iloc[0])\n",
        "candidate_skills = set(resume_df[\"resume_skills\"].iloc[0])\n",
        "\n",
        "print(\"Job Required Skills:\")\n",
        "print(job_required_skills)\n",
        "\n",
        "print(\"\\nCandidate Skills:\")\n",
        "print(candidate_skills)\n",
        "\n",
        "# Skill gap = skills required by job but missing in candidate\n",
        "missing_skills = job_required_skills - candidate_skills\n",
        "\n",
        "# Readiness score\n",
        "if len(job_required_skills) > 0:\n",
        "    readiness_score = (\n",
        "        (len(job_required_skills) - len(missing_skills))\n",
        "        / len(job_required_skills)\n",
        "    ) * 100\n",
        "else:\n",
        "    readiness_score = 0\n",
        "\n",
        "print(\"\\n❌ Missing Skills (Skill Gap):\")\n",
        "print(missing_skills)\n",
        "\n",
        "print(f\"\\n✅ Skill Readiness Score: {readiness_score:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbOfwV9WmgRo",
        "outputId": "b1335031-bb4d-4c57-998a-563278b34ab1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Job Required Skills:\n",
            "{'microsoft office', 'technical support', 'remote desktop'}\n",
            "\n",
            "Candidate Skills:\n",
            "{'machine learning', 'numpy', 'sql', 'tableau', 'git', 'pandas', 'css', 'java', 'python', 'html', 'deep learning', 'scikit', 'computer vision', 'docker', 'javascript'}\n",
            "\n",
            "❌ Missing Skills (Skill Gap):\n",
            "{'microsoft office', 'technical support', 'remote desktop'}\n",
            "\n",
            "✅ Skill Readiness Score: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================\n",
        "# FINAL CELL: Save Cleaned Skill Gap Data\n",
        "# 07_skillgap_cleaning.ipynb\n",
        "# =========================================\n",
        "\n",
        "import os\n",
        "\n",
        "# Create cleaned data directory\n",
        "os.makedirs(\"/content/data/cleaned\", exist_ok=True)\n",
        "\n",
        "# Save cleaned job skills data\n",
        "job_df[[\"job_title\", \"job_skills\"]].to_csv(\n",
        "    \"/content/data/cleaned/skillgap_job_cleaned.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "# Save cleaned resume skills data\n",
        "resume_df[[\"Category\", \"resume_skills\"]].to_csv(\n",
        "    \"/content/data/cleaned/skillgap_resume_cleaned.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"✅ Skill Gap cleaned datasets saved successfully!\")\n",
        "print(\"Saved files:\")\n",
        "print(\"- /content/data/cleaned/skillgap_job_cleaned.csv\")\n",
        "print(\"- /content/data/cleaned/skillgap_resume_cleaned.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88NzFuURm29m",
        "outputId": "6c418ba1-fce1-495a-9067-0ee124aaf25b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Skill Gap cleaned datasets saved successfully!\n",
            "Saved files:\n",
            "- /content/data/cleaned/skillgap_job_cleaned.csv\n",
            "- /content/data/cleaned/skillgap_resume_cleaned.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sNcYlG6drzyp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}